{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /Users/jk/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from modules.extraction.preprocessing import DocumentProcessing\n",
        "from modules.extraction.embedding import Embedding\n",
        "from modules.retrieval.index.bruteforce import FaissBruteForce\n",
        "from modules.retrieval.search import FaissSearch\n",
        "from modules.generator.question_answering import QA_Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 4 \n",
        "\n",
        "In a notebook called textwave/notebooks/demo_retrieval.ipynb, using all questions listed in `textwave/qa_resources/questions.tsv`, demonstrate your system's ability to retrieve the nearest neighbors. \n",
        "\n",
        "You will compare the retrieval performance of `all-MiniLM-L6-v2` embedding model and another embedding model of your choosing from the available list of [modelsLinks](https://sbert.net/docs/sentence_transformer/pretrained_models.html).  Measure the retrieval (ranking) performance of the two embedding models based on retrieved chunks being in the proper target article (see ArticleFile column in **textwave/qa_resources/questions.tsv**).\n",
        "\n",
        "For example, given a question with an associated ArticleFile as \"S08_set3_a4\" a true positive would be a chunk that is extracted from S08_set3_a4.txt.clean. You may choose to use default parameters/configuration for the other modules.\n",
        "\n",
        "> Note: you may refer to your IronClad index and search implementations. Place them in textwave/modules/retrieval/. Follow IronClads files structure for index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Params\n",
        "MODEL_NAMES = ['all-MiniLM-L6-v2', 'multi-qa-mpnet-base-cos-v1', 'multi-qa-distilbert-cos-v1', 'paraphrase-multilingual-MiniLM-L12-v2'] #\n",
        "CHUNKING_STRATEGY = 'sentence' # or 'fixed-length'\n",
        "STORAGE_DIR = '../storage/'\n",
        "FAISS_INDEX_DIR = '../storage/faiss_index/'\n",
        "DISTANCE_METRIC = 'cosine'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to load a serialized FAISS index instance from a file.\n",
        "def load_faiss_index(filepath):\n",
        "    with open(filepath, 'rb') as f:\n",
        "        instance = pickle.load(f)\n",
        "    return instance\n",
        "\n",
        "# Helper function to generate embeddings for a list of text\n",
        "def generate_embedding(inputs, embedding_model):\n",
        "    embeddings = []\n",
        "    for text in inputs:\n",
        "        embedding_vector = embedding_model.encode(text)\n",
        "        embeddings.append(embedding_vector)\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1032 non-empty questions/articlefiles found.\n",
            "The first 5 rows of the DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did his mother die of pneumonia?</td>\n",
              "      <td>no</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ArticleTitle                                           Question Answer  \\\n",
              "0  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...    yes   \n",
              "1  Abraham_Lincoln  Was Abraham Lincoln the sixteenth President of...   Yes.   \n",
              "2  Abraham_Lincoln  Did Lincoln sign the National Banking Act of 1...    yes   \n",
              "3  Abraham_Lincoln  Did Lincoln sign the National Banking Act of 1...   Yes.   \n",
              "4  Abraham_Lincoln                   Did his mother die of pneumonia?     no   \n",
              "\n",
              "  DifficultyFromQuestioner DifficultyFromAnswerer  ArticleFile  \n",
              "0                     easy                   easy  S08_set3_a4  \n",
              "1                     easy                   easy  S08_set3_a4  \n",
              "2                     easy                 medium  S08_set3_a4  \n",
              "3                     easy                   easy  S08_set3_a4  \n",
              "4                     easy                 medium  S08_set3_a4  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Read the TSV file into a DataFrame\n",
        "questions_df = pd.read_csv(\"../qa_resources/question.tsv\", sep=\"\\t\")\n",
        "\n",
        "questions_df = questions_df.dropna(subset=['Question','ArticleFile'])\n",
        "print(f\"{len(questions_df)} non-empty questions/articlefiles found.\")\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"The first 5 rows of the DataFrame:\")\n",
        "display(questions_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "questions = questions_df['Question'].tolist()  # Extract the 'Question' column as a list\n",
        "target_answers = questions_df['Answer'].tolist()  # Extract the 'Answer' column as a list\n",
        "target_files = questions_df['ArticleFile'].tolist()  # Extract the 'ArticleFile' column as a list\n",
        "\n",
        "assert len(questions) == len(target_answers) == len(target_files) == len(questions_df), \"Length of questions, answers, and files must match.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of documents: 150\n",
            "Total number of chunks: 2351\n"
          ]
        }
      ],
      "source": [
        "# Generate chucks from the documents\n",
        "documents = [os.path.join(STORAGE_DIR, f) for f in os.listdir(STORAGE_DIR) if f.endswith('.txt.clean')]\n",
        "print(f\"Total number of documents: {len(documents)}\")\n",
        "\n",
        "chunks_dict = defaultdict(list)\n",
        "\n",
        "# Iterate over the documents and chunk them\n",
        "for document in documents:\n",
        "    document_name = os.path.basename(document)[:-10]\n",
        "\n",
        "    # Initialize DocumentProcessing class\n",
        "    document_processing = DocumentProcessing()\n",
        "\n",
        "    if CHUNKING_STRATEGY == 'sentence':\n",
        "        chunks_dict[document_name].extend(document_processing.sentence_chunking(document, num_sentences=15, overlap_size=0))\n",
        "    elif CHUNKING_STRATEGY == 'fixed-length':\n",
        "        chunks_dict[document_name].extend(document_processing.fixed_length_chunking(document, chunk_size=256, overlap_size=0))\n",
        "\n",
        "# Get the chunks and document names into lists\n",
        "chunks = [item for sub_chunks in chunks_dict.values() for item in sub_chunks]\n",
        "document_names = [doc_name for doc_name in chunks_dict.keys() for _ in range(len(chunks_dict[doc_name]))]\n",
        "assert len(chunks) == len(document_names), \"Mismatch between chunks and document names\"\n",
        "\n",
        "# Print the number of chunks\n",
        "print(f\"Total number of chunks: {len(chunks)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With model all-MiniLM-L6-v2, 1032 question vectors and 2351 context vectors are generated.\n",
            "With model multi-qa-mpnet-base-cos-v1, 1032 question vectors and 2351 context vectors are generated.\n",
            "With model multi-qa-distilbert-cos-v1, 1032 question vectors and 2351 context vectors are generated.\n",
            "With model paraphrase-multilingual-MiniLM-L12-v2, 1032 question vectors and 2351 context vectors are generated.\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings for the questions and document chuncks as context\n",
        "question_vectors = {}\n",
        "context_vectors = {}\n",
        "\n",
        "# Generate embeddings for each model\n",
        "for model_name in MODEL_NAMES:\n",
        "    embedding_model = Embedding(model_name=model_name)\n",
        "    question_vectors[model_name] = generate_embedding(questions, embedding_model)\n",
        "    context_vectors[model_name] = generate_embedding(chunks, embedding_model)\n",
        "    print(f\"With model {model_name}, {len(question_vectors[model_name])} question vectors and {len(context_vectors[model_name])} context vectors are generated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index with model all-MiniLM-L6-v2 is saved in ../storage/faiss_index/faiss_index_all-MiniLM-L6-v2.pkl\n",
            "FAISS index with model multi-qa-mpnet-base-cos-v1 is saved in ../storage/faiss_index/faiss_index_multi-qa-mpnet-base-cos-v1.pkl\n",
            "FAISS index with model multi-qa-distilbert-cos-v1 is saved in ../storage/faiss_index/faiss_index_multi-qa-distilbert-cos-v1.pkl\n",
            "FAISS index with model paraphrase-multilingual-MiniLM-L12-v2 is saved in ../storage/faiss_index/faiss_index_paraphrase-multilingual-MiniLM-L12-v2.pkl\n"
          ]
        }
      ],
      "source": [
        "# Store vector embeddings of context chunks in a BruteForace index\n",
        "for model_name in MODEL_NAMES:\n",
        "    faiss_index = FaissBruteForce(dim=len(context_vectors[model_name][0]), metric=DISTANCE_METRIC)\n",
        "    faiss_index.add_embeddings(np.array(context_vectors[model_name]), metadata=document_names) # metadata is the document name\n",
        "    faiss_index.save(FAISS_INDEX_DIR + f\"faiss_index_{model_name}.pkl\")\n",
        "    print(f\"FAISS index with model {model_name} is saved in {FAISS_INDEX_DIR}faiss_index_{model_name}.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ModelName</th>\n",
              "      <th>Question</th>\n",
              "      <th>TargetAnswer</th>\n",
              "      <th>TargetFile</th>\n",
              "      <th>MetaResults</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set3_a4, S08_set3_a4, S08_set3_a4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set3_a4, S08_set3_a4, S08_set3_a4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set3_a4, S08_set3_a5, S08_set3_a4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set3_a4, S08_set3_a5, S08_set3_a4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>Did his mother die of pneumonia?</td>\n",
              "      <td>no</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set4_a4, S09_set4_a4, S08_set3_a10]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>Did his mother die of pneumonia?</td>\n",
              "      <td>No.</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set4_a4, S09_set4_a4, S08_set3_a10]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>How many long was Lincoln's formal education?</td>\n",
              "      <td>18 months</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set3_a4, S08_set3_a4, S08_set3_a4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>How many long was Lincoln's formal education?</td>\n",
              "      <td>18 months.</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set3_a4, S08_set3_a4, S08_set3_a4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>When did Lincoln begin his political career?</td>\n",
              "      <td>1832</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set3_a4, S08_set3_a4, S08_set3_a4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>all-MiniLM-L6-v2</td>\n",
              "      <td>When did Lincoln begin his political career?</td>\n",
              "      <td>1832.</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>[S08_set3_a4, S08_set3_a4, S08_set3_a4]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ModelName                                           Question  \\\n",
              "0  all-MiniLM-L6-v2  Was Abraham Lincoln the sixteenth President of...   \n",
              "1  all-MiniLM-L6-v2  Was Abraham Lincoln the sixteenth President of...   \n",
              "2  all-MiniLM-L6-v2  Did Lincoln sign the National Banking Act of 1...   \n",
              "3  all-MiniLM-L6-v2  Did Lincoln sign the National Banking Act of 1...   \n",
              "4  all-MiniLM-L6-v2                   Did his mother die of pneumonia?   \n",
              "5  all-MiniLM-L6-v2                   Did his mother die of pneumonia?   \n",
              "6  all-MiniLM-L6-v2      How many long was Lincoln's formal education?   \n",
              "7  all-MiniLM-L6-v2      How many long was Lincoln's formal education?   \n",
              "8  all-MiniLM-L6-v2       When did Lincoln begin his political career?   \n",
              "9  all-MiniLM-L6-v2       When did Lincoln begin his political career?   \n",
              "\n",
              "  TargetAnswer   TargetFile                               MetaResults  \n",
              "0          yes  S08_set3_a4   [S08_set3_a4, S08_set3_a4, S08_set3_a4]  \n",
              "1         Yes.  S08_set3_a4   [S08_set3_a4, S08_set3_a4, S08_set3_a4]  \n",
              "2          yes  S08_set3_a4   [S08_set3_a4, S08_set3_a5, S08_set3_a4]  \n",
              "3         Yes.  S08_set3_a4   [S08_set3_a4, S08_set3_a5, S08_set3_a4]  \n",
              "4           no  S08_set3_a4  [S08_set4_a4, S09_set4_a4, S08_set3_a10]  \n",
              "5          No.  S08_set3_a4  [S08_set4_a4, S09_set4_a4, S08_set3_a10]  \n",
              "6    18 months  S08_set3_a4   [S08_set3_a4, S08_set3_a4, S08_set3_a4]  \n",
              "7   18 months.  S08_set3_a4   [S08_set3_a4, S08_set3_a4, S08_set3_a4]  \n",
              "8         1832  S08_set3_a4   [S08_set3_a4, S08_set3_a4, S08_set3_a4]  \n",
              "9        1832.  S08_set3_a4   [S08_set3_a4, S08_set3_a4, S08_set3_a4]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize FAISS search to retrieve the top 3 results\n",
        "results = []\n",
        "for model_name in MODEL_NAMES:\n",
        "    # Load the FAISS index\n",
        "    faiss_index = load_faiss_index(FAISS_INDEX_DIR + f\"faiss_index_{model_name}.pkl\")\n",
        "    faiss_search = FaissSearch(faiss_index, metric=DISTANCE_METRIC)\n",
        "\n",
        "    # Perform the search for each question\n",
        "    for question_vector, question, target_answer, target_file in zip(question_vectors[model_name], questions, target_answers, target_files):\n",
        "        distances, indices, metadata = faiss_search.search(question_vector, k=3)\n",
        "\n",
        "        # Store the result\n",
        "        results.append({\n",
        "            'ModelName': model_name,\n",
        "            'Question': question,\n",
        "            'TargetAnswer': target_answer,\n",
        "            'TargetFile': target_file,\n",
        "            'MetaResults': metadata,\n",
        "        })\n",
        "\n",
        "# Convert the result list to a DataFrame and display the first 10 rows\n",
        "results = pd.DataFrame(results)\n",
        "display(results[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model all-MiniLM-L6-v2 made 823 correct answers for 1032 questions. Accuracy is 0.80\n",
            "Model multi-qa-mpnet-base-cos-v1 made 864 correct answers for 1032 questions. Accuracy is 0.84\n",
            "Model multi-qa-distilbert-cos-v1 made 849 correct answers for 1032 questions. Accuracy is 0.82\n",
            "Model paraphrase-multilingual-MiniLM-L12-v2 made 774 correct answers for 1032 questions. Accuracy is 0.75\n"
          ]
        }
      ],
      "source": [
        "# Get performance metrics for each model\n",
        "for model_name in MODEL_NAMES:\n",
        "    model_results = results[results['ModelName'] == model_name]\n",
        "\n",
        "    # Calculate the number of correct answers\n",
        "    correct_answers = 0 # True Positives\n",
        "    for index, row in model_results.iterrows():\n",
        "        if row['TargetFile'] in row['MetaResults']:\n",
        "            correct_answers+= 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct_answers / len(model_results)\n",
        "    print(f\"Model {model_name} made {correct_answers} correct answers for {len(model_results)} questions. Accuracy is {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Summary\n",
        "In this analysis, four different models are applied to encode 1032 questions and 150 documents(context). Then indices are built to retrieve the top 3 documents for each question. To evaluate the  performance across models, consistent chuncking (by sentence), indexing (FAISS bruteforce index) and retrieval methodologies (consine metric) were applied.\n",
        "\n",
        "According to the result, model `multi-qa-mpnet-base-cos-v1` shows the best performance with the highest accuracy rate of 0.84, following by model `multi-qa-distilbert-cos-v1` with accuracy rate of 0.82. The model `paraphrase-multilingual-MiniLM-L12-v2` demonstrates the worst performance for this case with accuracy score of 0.75. \n",
        "\n",
        "The model `multi-qa-mpnet-base-cos-v1` generally utilizes the more powerful MPNet architecture, explaining why it has higher accuracy. Notably, the multilingual model `paraphrase-multilingual-MiniLM-L12-v2` shows the lowest accuracy. While its multilingual capability can be beneficial in diverse linguistic contexts, it may sacrifice some accuracy compared to language-specific or English-optimized models.\n"
      ]
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "8aff0988-e607-4753-83a6-e87d5b5717d6",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "pytorch_gpu_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
